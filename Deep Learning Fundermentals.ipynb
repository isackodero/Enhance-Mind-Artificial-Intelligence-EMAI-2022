{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3258aaad",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "<h1>DEEP LEARNING FUNDAMENTALS</h1> <br><br>\n",
    "<h4>Isack Odero<h4/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f9010e6",
   "metadata": {},
   "source": [
    "<img src='img/zoom.jpg'><br><h3>What is Deep Learning</h3><br><img src='img/Screenshot from 2022-11-15 21-56-18.png'><br><h3>Why Deep Learning and Why Now ?</h3><br><h4>Why Deep Learning</h4><br><p>Hand engineer features are<li>Time consuming</li><li>Brittle</li><li>Not scalable in practice</li></p><br><img src='img/Screenshot from 2022-11-15 22-08-35.png'><br><div><h4>Why Now ? </h4><br><img src='img/Screenshot from 2022-11-15 22-30-22.png'><br><p>Neural Networks dates back a decades, so why now?</p><br><p><lh>Big Data<lh><li>Large Datasets</li><li>Easier Collection</li><li>Storage</li> <br><img src='img/Screenshot from 2022-11-17 13-48-43.png'></p><br><p><lh>Hardware<lh><li>Graphics</li><li>Processing Units(GPU)</li><li>Massive Parallelizable</li> <br><img src='img/Screenshot from 2022-11-17 13-50-24.png'></p><br><p><lh>Software<lh><li>Improved Techniques</li><li>New Models</li><li>Toolboxes</li><br><img src='img/Screenshot from 2022-11-17 13-51-11.png'></p></div><br><h3 >The Perceptron</h3><br><h4>The structural building block of deep learning</h4></p><br><h5>The Perceptron: Forward Propagation</h5><br><img src='img/Screenshot from 2022-11-15 22-45-20.png'><br><img src='img/Screenshot from 2022-11-15 22-46-13.png'><br><img src='img/Screenshot from 2022-11-15 22-48-18.png'><br><img src='img/Screenshot from 2022-11-15 22-49-18.png'><br><img src='img/Screenshot from 2022-11-15 22-50-13.png'><br><h5>Activation Function</h5><br><img src='img/Screenshot from 2022-11-15 22-52-29.png'><br><h4>Common Activation Function</h4><br><img src='img/Screenshot from 2022-11-15 22-54-12.png'><br><h4>Importance of Activation Functions</h4><br><p>The purpose of activation function is to Intrduce <b>non-Linearities</b> into the network</p><br><img src='img/Screenshot from 2022-11-15 22-58-28.png'><br><img src='img/Screenshot from 2022-11-15 22-59-24.png'><br><img src='img/Screenshot from 2022-11-15 23-00-23.png'><br><h4>The Perceptron: Example</h4><br><img src='img/Screenshot from 2022-11-15 23-12-39.png'><br><img src='img/Screenshot from 2022-11-15 23-13-36.png'><br><img src='img/Screenshot from 2022-11-15 23-14-55.png'><br><img src='img/Screenshot from 2022-11-16 00-11-20.png'><br><img src='img/Screenshot from 2022-11-16 00-12-44.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4b4f617",
   "metadata": {},
   "source": [
    "<img src='img/Screenshot from 2022-11-15 23-27-08.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c425e94",
   "metadata": {},
   "source": [
    "<h3>Building Neural Networks with Perceptron</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fc99b82",
   "metadata": {},
   "source": [
    "<h4>The Perceptron: Simplified</h4><br><img src='img/Screenshot from 2022-11-15 23-35-26.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab2ab467",
   "metadata": {},
   "source": [
    "<img src='img/Screenshot from 2022-11-15 23-36-37.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae15f802",
   "metadata": {},
   "source": [
    "<img src='img/Screenshot from 2022-11-15 23-37-28.png'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8acfbb8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "20573a67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "device=\"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "12d0bcaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Perceptron(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.flatten=nn.Flatten()\n",
    "        self.layers=nn.Sequential(\n",
    "            nn.Linear(2,1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x=self.flatten(x)\n",
    "        y_hat=self.layers(x)\n",
    "        return y_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4713a2df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perceptron(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=2, out_features=1, bias=True)\n",
      "    (1): Sigmoid()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model=Perceptron().to(device)\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "95f5a309",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.3478]], grad_fn=<SigmoidBackward0>)\n"
     ]
    }
   ],
   "source": [
    "x=torch.tensor([[-1,2]], dtype=torch.float)\n",
    "\n",
    "y=model(x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e503e6a8",
   "metadata": {},
   "source": [
    "<h3>Single Layer Neural Network</h3><br><img src='img/Screenshot from 2022-11-16 00-50-55.png'><br><img src='img/Screenshot from 2022-11-16 00-53-02.png'><br><img src='img/Screenshot from 2022-11-16 00-53-02.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87b394a6",
   "metadata": {},
   "source": [
    "<img src='img/Screenshot from 2022-11-16 00-54-38.png'><br><img src='img/Screenshot from 2022-11-16 00-55-48.png'><br><img src='img/Screenshot from 2022-11-16 00-56-24.png'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e60c7821",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SingleLayerNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.flatten=nn.Flatten()\n",
    "        self.layers=nn.Sequential(\n",
    "            nn.Linear(32*32,200),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(200, 2)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x=self.flatten(x)\n",
    "        y_hat=self.layers(x)\n",
    "        return y_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b15a51e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SingleLayerNN(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=1024, out_features=200, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=200, out_features=2, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model=SingleLayerNN()\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8b42adb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "image=torch.rand(1,32,32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9dd9ad67",
   "metadata": {},
   "outputs": [],
   "source": [
    "y=model(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dc94c869",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0910, -0.1547]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad3e5f86",
   "metadata": {},
   "source": [
    "<h3>Deep Neural Network</h3><br><img src='img/Screenshot from 2022-11-16 01-14-00.png'><br><img src='img/Screenshot from 2022-11-16 01-14-33.png'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6d7ed00d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeepNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.flatten=nn.Flatten()\n",
    "        self.layers=nn.Sequential(\n",
    "            nn.Linear(32*32,200),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(200, 200),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(200,100),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(100,10)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x=self.flatten(x)\n",
    "        y_hat=self.layers(x)\n",
    "        return y_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6c15e18f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DeepNN(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=1024, out_features=200, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=200, out_features=200, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=200, out_features=100, bias=True)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=100, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model=DeepNN()\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5c94c463",
   "metadata": {},
   "outputs": [],
   "source": [
    "y=model(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9b419f50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "print(len(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1753572",
   "metadata": {},
   "source": [
    "<h4>Applying Neural Networks</h4><br><br><h5>Example Problem</h5><br><br><h5>Will You Pass if we decide to give an exam about the EMAI Conferrence presentations</h5><br><p>Let's start with a simple two feature model</p>\n",
    "\n",
    "<br><br><p>X_1= Number of lectures you attend<br> X_2 = Hours spent on the final project</p><br><img src='img/Screenshot from 2022-11-16 01-31-53.png'><br><img src='img/Screenshot from 2022-11-16 01-32-39.png'><br><img src='img/Screenshot from 2022-11-16 01-33-36.png'><br><img src='img/Screenshot from 2022-11-16 01-34-41.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ab01430",
   "metadata": {},
   "source": [
    "<h3>Quantifying Loss</h3><br><p>The LOSS of this will measures the cost incurrect predictions<p/><br><img src='img/Screenshot from 2022-11-16 01-38-12.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1beb0344",
   "metadata": {},
   "source": [
    "<h3>Cost Function</h3><br><p>The Cost Function measures the total loss over our entire datasets</p><br><img src='img/Screenshot from 2022-11-16 01-39-58.png'><br><img src='img/Screenshot from 2022-11-16 01-40-54.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92ff9d34",
   "metadata": {},
   "source": [
    "<p>Here we will look two types of Loss</p><br><li>Binary Cross Entropy Loss</li><li>Mean Squared Error Loss</li>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c0d115a",
   "metadata": {},
   "source": [
    "<h5>Binary Cross Entropy Loss</h5><br><p>This is used with the models that output a probability between 0 and 1</p><br><img src='img/Screenshot from 2022-11-16 01-48-41.png'><br><img src='img/Screenshot from 2022-11-16 01-49-29.png'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7bd7daf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "Loss=nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35b17f5e",
   "metadata": {},
   "source": [
    "<h5>Mean Squared Error Loss</h5><br><p>This is used with the regression models that output continuous real number</p><br><img src='img/Screenshot from 2022-11-15 22-07-39.png'><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1e678b07",
   "metadata": {},
   "outputs": [],
   "source": [
    "Loss = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16ba1264",
   "metadata": {},
   "source": [
    "<h3>Deep Neural Network</h3><br><h4>Loss Optimization</h4><br><p>We want to find the network weights that achieve the lowest loss</p><br><img src='img/Screenshot from 2022-11-15 22-18-41.png'><br><img src='img/Screenshot from 2022-11-15 22-19-37.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c99500eb",
   "metadata": {},
   "source": [
    "<img src='img/Screenshot from 2022-11-15 22-20-20.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22b64d03",
   "metadata": {},
   "source": [
    "<img src='img/Screenshot from 2022-11-15 22-22-13.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "029e7a5b",
   "metadata": {},
   "source": [
    "<img src='img/Screenshot from 2022-11-15 22-22-54.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ebb7d8e",
   "metadata": {},
   "source": [
    "<h5>If you will repeat the above process, that is what we call Gradient Descent</h5>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22a12fba",
   "metadata": {},
   "source": [
    "<img src='img/Screenshot from 2022-11-15 22-23-41.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef8dfe14",
   "metadata": {},
   "source": [
    "<h3>Gradient Descent</h3>\n",
    "<lh><b>Algorithm</b></lh><br><li>Initialize weights randomly <img src='img/Screenshot from 2022-11-15 22-26-45.png'></li><li>Loop until converging</li><br><li>Compute Gradient <img src='img/Screenshot from 2022-11-15 22-31-09.png'></li><li>Update weights <img src='img/Screenshot from 2022-11-15 22-32-21.png'></li><li>Return weights</li><br><img src='img/Screenshot from 2022-11-17 13-14-22.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d64f4904",
   "metadata": {},
   "source": [
    "<p>This approach have one problem : the gradients can be very Computationally Intensive to compute</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e270225c",
   "metadata": {},
   "source": [
    "<h3>Gradient Descent</h3>\n",
    "<lh><b>Algorithm</b></lh><br><li>Initialize weights randomly <img src='img/Screenshot from 2022-11-15 22-26-45.png'></li><li>Loop until converging</li><br><li>Pick single data point <img src='img/Screenshot from 2022-11-17 13-19-51.png'> </li><br><li>Compute Gradient <img src='img/Screenshot from 2022-11-17 13-20-58.png'></li><li>Update weights <img src='img/Screenshot from 2022-11-15 22-32-21.png'></li><li>Return weights</li><br><img src='img/Screenshot from 2022-11-17 13-14-22.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eb33752",
   "metadata": {},
   "source": [
    "<p>Now using <br><li>Compute Gradient <img src='img/Screenshot from 2022-11-17 13-20-58.png'></li> <br>it become easy to compute but the problem is it is produce very noisy (stochastic)</p><br><p>Now to solve that problem the Stochastic Gradient Descent is used</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58f347b5",
   "metadata": {},
   "source": [
    "<h3>Stochastic Gradient Descent</h3>\n",
    "<lh><b>Algorithm</b></lh><br><li>Initialize weights randomly <img src='img/Screenshot from 2022-11-15 22-26-45.png'></li><li>Loop until converging</li><br><li>Pick batch of <i>B</i> data points </li><br><li>Compute Gradient <img src='img/Screenshot from 2022-11-17 13-31-49.png'></li><li>Update weights <img src='img/Screenshot from 2022-11-15 22-32-21.png'></li><li>Return weights</li><br><img src='img/Screenshot from 2022-11-17 13-14-22.png'><br><p><i>Now this become Fast to compute and a much better estimate of the true gradient</i></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3470712a",
   "metadata": {},
   "source": [
    "<h3>Mini-batches while training</h3><br><h4>More accurate estination of gradient</h4><br><li>Smoother convergen</li><br><li>Allows for larger learning rates</li>\n",
    "\n",
    "<br><h4>Mini-batches lead to fast trianing!</h4><br><li>can parallelize cotation  +   achieve significant speed increases on GPU's</li>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "635bea42",
   "metadata": {},
   "source": [
    "<h3>Computing Gradients: Backpropagation</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d4dcb2f",
   "metadata": {},
   "source": [
    "<img src='img/Screenshot from 2022-11-17 02-12-43.png'><br><p>How does a small change in one weight (eg.W_2) affect the final loss J(W)?</p><br><img src='img/Screenshot from 2022-11-17 02-15-05.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44a986e7",
   "metadata": {},
   "source": [
    "<img src='img/Screenshot from 2022-11-17 02-17-10.png'><br><img src='img/Screenshot from 2022-11-17 02-18-22.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8cb97ac",
   "metadata": {},
   "source": [
    "<img src='img/Screenshot from 2022-11-17 02-22-26.png'><br><img src='img/Screenshot from 2022-11-17 02-23-09.png'><br><img src='img/Screenshot from 2022-11-17 02-24-46.png'><br><p>Repeat this for every weight in the network using gradients from later layers</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66c6992b",
   "metadata": {},
   "source": [
    "<h3>Neural Network in Practice: Optimization</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7262cc12",
   "metadata": {},
   "source": [
    "<img src='img/Screenshot from 2022-11-15 22-23-41.png'><br><h4>Loss Functions Can Be Difficult to Optimize</h4><br><br><h5>Remember:</h5><br><p>Optimization through gradient descent</p><br><img src='img/Screenshot from 2022-11-17 02-31-38.png'><br><img src='img/Screenshot from 2022-11-17 02-32-28.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b07c2530",
   "metadata": {},
   "source": [
    "<h4>Setting the Learning Rate</h4>\n",
    "<br><p>Small Lerning Rate converge and gets stuck in False local minima</p><br><br><p>Large Lerning Rate overshoot, become unstable and diverge</p><br><br><p>Stable Lerning Rate converge smoothly and avoid local minima</p><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01f94ca2",
   "metadata": {},
   "source": [
    "<h4>How to deal with this?</h4>\n",
    "\n",
    "<br><lh>Idea 1:</lh><li>Try lots of different learning rates and see what works \"just  right\" </li><br><br><lh>Idea 2:</lh><li>Do something smarter! <br> Design an adaptive learning rate that \"adapts\" to the landscape</li>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b426a527",
   "metadata": {},
   "source": [
    "<h4>Adaptive Learning Rates</h4>\n",
    "<br><lh>- Learnign Rate are not longer fixed </lh><br><br><lh>- Can be made larger or smaller depending on </lh><br><li>how large gradient is </li><br><li>How fast learning is happening</li><br><li>size of particular weights</li></li>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2edb5a81",
   "metadata": {},
   "source": [
    "<h3>How to adjust learning rate using Pytorch</h3>\n",
    "<p><u><i>torch.optim.lr_scheduler</i></u> provides several methods to adjust the learning rate based on the number of epochs.</p>"
   ]
  },
  {
   "cell_type": "raw",
   "id": "6f321004",
   "metadata": {},
   "source": [
    "#define your model\n",
    "model = model\n",
    "\n",
    "#choose your optimizer\n",
    "optimizer = SGD(model.parameters(), 0.1)\n",
    "\n",
    "#define how you want to adjust your learnign rate\n",
    "scheduler = ExponentialLR(optimizer, gamma=0.9)\n",
    "\n",
    "#training loop\n",
    "for epoch in range(20):\n",
    "    \n",
    "    #load datasets\n",
    "    for input, target in dataset:\n",
    "        \n",
    "        #zero all of your previous gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        #forward propagation\n",
    "        output = model(input)\n",
    "        \n",
    "        #loss function\n",
    "        loss = loss_fn(output, target)\n",
    "        \n",
    "        #back propagation\n",
    "        loss.backward()\n",
    "        \n",
    "        #optimization\n",
    "        optimizer.step()\n",
    "        \n",
    "    #update your learning rate after every epoch\n",
    "    scheduler.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10d55dac",
   "metadata": {},
   "source": [
    "<h3>Gradient Descent Algorithms</h3><br><li>SGD               <i>{{ torch.optim.SGD(**args) }}</i></li><br><li>Adam  <i>{{torch.optim.Adam(**args) }}</i></li><br><li>Adafelta  <i>{{torch.optim.Adafelta(**args) }}</i></li><br><li>Adagrad  <i>{{torch.optim.Adagrad(**args) }}</i></li><br><li>RMSProp  <i>{{torch.optim.RMSProp(**args) }}</i></li>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a404553",
   "metadata": {},
   "source": [
    "<h4>Putting it all together</h4>"
   ]
  },
  {
   "cell_type": "raw",
   "id": "db10877e",
   "metadata": {},
   "source": [
    "for input, target in dataset:\n",
    "    #Clearning the old gradients from the last step\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    #Forward Propagation\n",
    "    output = model(input)\n",
    "    \n",
    "    #calculation loss\n",
    "    loss = loss_fn(output, target)\n",
    "    \n",
    "    #Calculating gradients of the loss w.r.t weights\n",
    "    loss.backward()\n",
    "    \n",
    "    #Taking steps toward local minima\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbba1b25",
   "metadata": {},
   "source": [
    "<h1>Now Let Make all of that make sense</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2a55e7a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries\n",
    "import torch\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7518a037",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
